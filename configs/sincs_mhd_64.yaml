# SINCS Training Config for Mhd 64
# Dynamic fields: magnetic_field (3) + velocity (3)
# Optimized for Cerebras CSX with static/dynamic field splitting

trainer:
  init:
    seed: 42
    model_dir: sincs_mhd_64_hd1024
    backend:
      backend_type: CSX
      cluster_config:
        num_workers_per_csx: 1
        mount_dirs:
          - /cra-1272/PhysicsAlchemists/datasets
          - /cra-1272/PhysicsAlchemists/WellImplementation/Well/modelzoo/src
        python_paths:
          - /cra-1272/PhysicsAlchemists/WellImplementation/Well/modelzoo/src
    model:
      name: sincs
      input_dim: 4
      output_dim: 7
      hidden_dim: 1024
      num_hidden_layers: 4
      omega_0: 30.0
      omega_hidden: 30.0
      use_fourier_encoding: true
      encoding_levels: 10
      dropout: 0.0
      loss_type: mse
      to_float16: false
    optimizer:
      Adam:
        lr: 0.0001
        betas: [0.9, 0.999]
        eps: 1.0e-08
        weight_decay: 1.0e-05
    schedulers:
    - SequentialLR:
        schedulers:
        - LinearLR:
            initial_learning_rate: 0.0
            end_learning_rate: 0.0001
            total_iters: 5000
        - CosineDecayLR:
            initial_learning_rate: 0.0001
            end_learning_rate: 0.00001
            total_iters: 45000
    precision:
      enabled: false
    loop:
      max_steps: 50000
    checkpoint:
      steps: 10000
    logging:
      log_steps: 100
  fit:
    train_dataloader:
      data_processor: SINCSDataProcessor
      data_dir: /cra-1272/PhysicsAlchemists/datasets
      dataset_name: MHD_64
      split: train
      trajectory_idx: 0
      num_timesteps: 15
      batch_size: 16384
      num_samples_per_epoch: 500000
      shuffle: true
      shuffle_seed: 42
      num_workers: 0
      prefetch_factor: 2
      persistent_workers: false
      drop_last: true
      use_fake_data: false
      split_static_dynamic: true
      dynamic_fields_only: true
      normalize_fields: true
